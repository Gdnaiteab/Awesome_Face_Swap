# Awesome Face Swapping
Awesome Faceswap papers&amp;code&amp;datasets&amp;.. collection

##  Papers

### 2023

| Title                                                        |   Venue   |                    Dataset                    |                             PDF                              |                             CODE                             |
| :----------------------------------------------------------- | :-------: | :-------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| StyleIPSB: Identity-Preserving Semantic Basis of StyleGAN for High Fidelity Face Swapping | CVPR 2023 | FFHQ<br>CelebA<br>CelebAHQ<br>FaceForensics++ | [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_StyleIPSB_Identity-Preserving_Semantic_Basis_of_StyleGAN_for_High_Fidelity_Face_CVPR_2023_paper.pdf) |         [CODE](https://github.com/a686432/StyleIPSB)         |
| MagicAnimate: Temporally Consistent Human Image Animation using Diffusion Model |     -     |             TikTok <br>TED-talks              |         [PDF](https://arxiv.org/pdf/2311.16498.pdf)          |   [CODE](https://github.com/magic-research/magic-animate)    |
| Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation |     -     |          UBC fashion video<br>TikTok          |         [PDF](https://arxiv.org/pdf/2311.17117.pdf)          | [CODE](https://github.com/HumanAIGC/AnimateAnyone)<br> |
| DreaMoving: A Human Video Generation Framework based on Diffusion Models |     -     |             Around 1,000 high-quality videos of human dance from the Internet              |         [PDF](https://arxiv.org/pdf/2312.05107.pdf)          |   [CODE](https://github.com/dreamoving/dreamoving-project)    |

### 2022

| Title                                                        |   Venue   |                          Dataset                           |                      PDF                      |                         CODE                          |
| :----------------------------------------------------------- | :-------: | :--------------------------------------------------------: | :-------------------------------------------: | :---------------------------------------------------: |
| MobileFaceSwap: A Lightweight Framework for Video Face Swapping | AAAI 2022 |                      FaceForensics++                       | [PDF](https://arxiv.org/pdf/2201.03808v1.pdf) | [CODE](https://github.com/Seanseattle/MobileFaceSwap) |
| FaceOff: A Video-to-Video Face Swapping System               | WACV 2023 |                   V2VFaceSwap<br>YouTube                   | [PDF](https://arxiv.org/pdf/2208.09788v1.pdf) |   [CODE](https://github.com/skymanaditya1/FaceOff)    |
| DiffFace: Diffusion-based Face Swapping with Facial Guidance |     -     |     FFHQ<br>FaceForensics++<br>Metfaces<br>Disney Face     |  [PDF](https://arxiv.org/pdf/2212.13344.pdf)  |      [CODE](https://github.com/hxngiee/DiffFace)      |
| High-Resolution Image Synthesis with Latent Diffusion Models | CVPR 2022 | CelebAHQ<br>FFHQ<br>ImageNet<br>LSUN<br>OpenImages<br>COCO |  [PDF](https://arxiv.org/pdf/2112.10752.pdf)  |  [CODE](https://github.com/CompVis/latent-diffusion)  |

### 2021

| Title                                                                                      |   Venue   |              Dataset              |                                                                              PDF                                                                               |                      CODE                      |
|:------------------------------------------------------------------------------------------ |:---------:|:---------------------------------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------:|
| DeepFaceLab: Integrated, flexible and extensible face-swapping framework | PR 2023 | DFDC<br>FaceForensics++ | [PDF](https://arxiv.org/pdf/2005.05535.pdf) | [CODE](https://github.com/iperov/DeepFaceLab) |
| HifiFace: 3D Shape and Semantic Prior Guided High Fidelity Face Swapping | IJCAI 2021 | FaceForensics++ | [PDF](https://arxiv.org/pdf/2106.09965v1.pdf) | [CODE](https://github.com/maum-ai/hififace) |

### 2020

| Title                                                        |   Venue   | Dataset  |                     PDF                     |                    CODE                     |
| :----------------------------------------------------------- | :-------: | :------: | :-----------------------------------------: | :-----------------------------------------: |
| LUVLi Face Alignment: Estimating Landmarks' Location, Uncertainty, and Visibility Likelihood | CVPR 2020 | MERL-RAV | [PDF](https://arxiv.org/pdf/2004.02980.pdf) | [CODE](https://github.com/abhi1kumar/LUVLi) |



### 2019

| Title                                                        |   Venue   |                           Dataset                            |                     PDF                     |                             CODE                             |
| :----------------------------------------------------------- | :-------: | :----------------------------------------------------------: | :-----------------------------------------: | :----------------------------------------------------------: |
| FSGAN: Subject Agnostic Face Swapping and Reenactment        | ICCV 2019 | IJB-C<br>VGGface2<br>CelebA<br>Figaro<br>LFW<br>FaceForensics++ | [PDF](https://arxiv.org/pdf/1908.05932.pdf) |         [CODE](https://github.com/YuvalNirkin/fsgan)         |
| Accurate 3D Face Reconstruction with Weakly-Supervised Learning: From Single Image to Image Set | CVPR 2019 |               MICC<br>FaceWarehouse<br>BU-3DFE               | [PDF](https://arxiv.org/pdf/1903.08527.pdf) | [CODE](https://github.com/microsoft/Deep3DFaceReconstruction) |




## Related Works

| Title                                                        | Venue |     Dataset      |                     PDF                     | CODE |
| :----------------------------------------------------------- | :---: | :--------------: | :-----------------------------------------: | :--: |
| Lumiere: A Space-Time Diffusion Model for Video Generation | - | **Train**:<br>videos along with text caption<br>**Val:**<br>a collection of 113 text prompts<br>UCF101 | [PDF](https://arxiv.org/pdf/2401.12945.pdf) |                          -                          |
| Effective Whole-body Pose Estimation with Two-stages Distillation | ICCV2023 |     UBody<br>COCO<br>**Val:**<br>UBody<br>COCO-WholeBody     | [PDF](https://arxiv.org/pdf/2307.15880.pdf) | [CODE](https://github.com/IDEA-Research/DWPose) |
| IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models | - | **Train:**<br>LAION-2B<br>COYO-700M<br>**Val:**<br>COCO2017 | [PDF](https://arxiv.org/pdf/2308.06721.pdf) | [CODE](https://github.com/tencent-ailab/IP-Adapter) |
| Enhancing Facial Classification and Recognition using 3D Facial Models and Deep Learning |   -   | KDEF<br>FEI Face | [PDF](https://arxiv.org/pdf/2312.05219.pdf) |  -   |
| AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning |     -     |          video          |         [PDF](https://arxiv.org/pdf/2307.04725.pdf)     |  - |
| DisCo: Disentangled Control for Realistic Human Dance Generation |   -   | COCO | [PDF](https://arxiv.org/pdf/2307.00040.pdf) |  [CODE](https://github.com/Wangt-CN/DisCo)   |

##  Projects

| Title | URL|              Introduction              |
|:---------: |:---------:|:---------------------------------:|
| <center>FaceChain</center> | [FaceChain](https://github.com/modelscope/facechain) | FaceChain is a deep-learning toolchain for generating a Digital-Twin of someone, with a minimum of 1 portrait-photo. |
| <center>AnimateAnyone</center> | [Animate Anyone](https://github.com/HumanAIGC/AnimateAnyone) | The official edition of Animate Anyone. Still **not open source**. |
| <center>Moore-AnimateAnyone</center> | [Moore-Animate Anyone](https://github.com/MooreThreads/Moore-AnimateAnyone) | Open Source and have Inference Codes, Pretrained Weights, Training Scripts.üòç<br>This project reproduces Animate Anyone. To align the results demonstrated by the original paper, it adopt various approaches and tricks, which may differ somewhat from the `Animate Anyone` and `Open-Animate Anyone`. |
| <center>Open-AnimateAnyone</center> | [Open-Animate Anyone](https://github.com/guoqincode/Open-AnimateAnyone) | Open Source but **NO PRETRAINED WEIGHTS!**<br>`Animate Anyone` is still closed-source according to official terms, and the URL in this table is one of its implementation by Qin Guo. This project is an image2video approch built upon magic-animate and AnimateDiff, capable of animating arbitrary characters. |
| <center>DeepFakes</center>|[DeepFakes](https://deepfakesweb.com) | Deepfakes App is closed-source online deepfake software that works in the cloud. Users need to do is upload videos and click a button,and the app will does the rest.|
| <center>EasyPhoto</center> | [EasyPhoto](https://github.com/aigc-apps/sd-webui-EasyPhoto) | EasyPhoto is a Webui UI plugin based on stable diffusion for generating AI portraits that can be used to train digital doppelgangers relevant to users.   |
| <center>FaceSwap</center> | [FaceSwap](https://github.com/deepfakes/faceswap/tree/master) | Faceswap is a GAN-based deepfake open-source tool on github. it provides an easy-to-use GUI interface to facilitate operations such as training and face-swapping. |
|<center> SwapFace</center> |[SwapFace](https://swapface.org/#/tutorial) | SwapFace is a closed-source deepfake tool for Windows that provides an easy-to-use GUI interface to enable users to accomplish one-click face swapping tasks in a foolproof way. |
| <center>Inswapper</center> | [Inswapper](https://github.com/haofanwang/inswapper) | It is a powerful face swap model that makes this happen based on insightface.  |
| <center>Roop</center> | [Roop](https://github.com/s0md3v/roop) | It is a one-click deepfake model on github. it enables replacing the face in the original video with just a single image without dataset and training. |
| <center>Vid2DensePose</center> | [Vid2DensePose](https://github.com/Flode-Labs/vid2densepose) | The Vid2DensePose is a powerful tool designed for applying the DensePose model to videos, generating detailed "Part Index" visualizations for each frame. This tool is exceptionally useful for enhancing animations, particularly when used in conjunction with MagicAnimate for temporally consistent human image animation. |

##  Datasets
### FFHQ
Introduced by Karras et al. in  [Style-Based Generator Architecture for Generative Adversarial Networks](https://arxiv.org/abs/1812.04948v3).

Flickr-Faces-HQ (FFHQ) consists of 70,000 high-quality PNG images at 1024√ó1024 resolution and contains considerable variation in terms of age, ethnicity and image background. It also has good coverage of accessories such as eyeglasses, sunglasses, hats, etc. The images were crawled from Flickr, thus inheriting all the biases of that website, and automatically aligned and cropped using dlib. Only images under permissive licenses were collected. Various automatic filters were used to prune the set, and finally Amazon Mechanical Turk was used to remove the occasional statues, paintings, or photos of photos.

Source: http:https://github.com/NVlabs/ffhq-dataset
### YouTube Faces DB
Introduced by Wolf et al. in [Face recognition in unconstrained videos with matched background similarity](https://ieeexplore.ieee.org/document/5995566).

YouTube Faces DB dataset contains 3,425 videos of 1,595 different people. All the videos were downloaded from YouTube. An average of 2.15 videos are available for each subject. The shortest clip duration is 48 frames, the longest clip is 6,070 frames, and the average length of a video clip is 181.3 frames.

Source: https://www.cs.tau.ac.il/~wolf/ytfaces/
### FaceForensics++
Introduced by R√∂ssler et al. in [FaceForensics: A Large-scale Video Dataset for Forgery Detection in Human Faces](https://arxiv.org/abs/1803.09179).

FaceForensics is a video dataset consisting of more than 500,000 frames containing faces from 1004 videos that can be used to study image or video forgeries. All videos are downloaded from Youtube and are cut down to short continuous clips that contain mostly frontal faces. This dataset has two versions:
* Source-to-Target: where the authors reenact over 1000 videos with new facial expressions extracted from other videos, which e.g. can be used to train a classifier to detect fake images or videos.
* Selfreenactment: where the authors use Face2Face to reenact the facial expressions of videos with their own facial expressions as input to get pairs of videos, which e.g. can be used to train supervised generative refinement models.

Source: https://github.com/ondyari/FaceForensics
### DFDC
Introduced by Dolhansky et al. in [The Deepfake Detection Challenge (DFDC) Preview Dataset](https://arxiv.org/abs/1910.08854).

The DFDC (Deepfake Detection Challenge) is a dataset for deepface detection consisting of more than 100,000 videos.

The DFDC dataset consists of two versions:
* Preview dataset. with 5k videos. Featuring two facial modification algorithms.
* Full dataset, with 124k videos. Featuring eight facial modification algorithms.

Source: https://ai.meta.com/datasets/dfdc/
### KDEF & AKDEF
Introduced by Lundqvist et al. in [The Karolinska Directed Emotional Faces (KDEF)](https://ki.se/en/cns/resources#heading-2).

The Karolinska Directed Emotional Faces (KDEF) is a set of totally 4900 pictures of human facial expressions. The set of pictures contains 70 individuals displaying 7 different emotional expressions. Each expression is viewed from 5 different angles.
The Averaged Karolinska Directed Emotional Faces (AKDEF) is a set of totally 70 pictures of human facial expressions. The set of pictures contains an averaged female and an averaged male displaying 7 different emotional expressions. Each expression is viewed from 5 different angles.

Source: https://kdef.se/
### Fashion Video Dataset
Introduced by Zablotskaia et al. in [Fashion Video Dataset](https://arxiv.org/abs/1910.09139).

The Fashion dataset introduced in the BMVC2019 paper ‚ÄúDwNet: Dense warp-based network for pose-guided human video generation‚Äù. 

Source: https://vision.cs.ubc.ca/datasets/fashion/
##  Acknowledgements
This page is made by [Bohuan Qu](https://github.com/Gdnaiteab),[Yize Cai](https://github.com/OskarJoa),[Xizhe Wu](https://github.com/SeverusNg), [Yuxuan He](https://github.com/Herython) all of whom are students of Dalian University of Technology, China.
